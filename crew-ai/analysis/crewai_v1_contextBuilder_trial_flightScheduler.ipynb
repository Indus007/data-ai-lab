{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from datetime import date, timedelta, datetime\n",
    "\n",
    "from google.cloud import aiplatform, bigquery\n",
    "from langchain_google_vertexai import VertexAI\n",
    "import pandas as pd\n",
    "from pandas import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Crew, Agent, Task, Process\n",
    "from langchain.tools import tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv('.env')\n",
    "client = os.getenv('CLIENT_DATASET_NAME')\n",
    "project_id = os.getenv('PROJECT_ID')\n",
    "print(client, project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Initialize llm\"\"\"\n",
    "aiplatform.init()\n",
    "llm_0=VertexAI(model_name='gemini-2.5-flash-001', candidate_count=1, temperature=0.4, max_tokens= 1024)\n",
    "llm_1=VertexAI(model_name='gemini-2.5-flash-001', candidate_count=1, temperature=0.4, max_tokens= 1024)\n",
    "llm_2=VertexAI(model_name='gemini-2.5-flash-001', candidate_count=1, temperature=0.4, max_tokens= 1024)\n",
    "# llm=ChatVertexAI(model_name='chat-bison@001')\n",
    "# llm = ChatVertexAI(model_name='codechat-bison@001')\n",
    "print(llm_0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def responseParser(output:str, key:str='text'):\n",
    "    \"\"\"Parses the output. default output key is 'text' \"\"\"\n",
    "    output=output.replace('```json','')\n",
    "    output=output.removeprefix('```json')\n",
    "    output=output.replace('```','')\n",
    "    output = output.lstrip()\n",
    "    # output = json.loads(output)\n",
    "    # print(output)\n",
    "    # return output[key]\n",
    "    return output\n",
    "\n",
    "def saveInsights(task_output):\n",
    "    current_datetime = datetime.now()\n",
    "    formatted_datetime = current_datetime.strftime('%Y%m%d-%H%M')\n",
    "    filename = f\"{formatted_datetime}.json\"\n",
    "    task_output = str(task_output)\n",
    "    task_output = responseParser(task_output)\n",
    "    # print(task_output)\n",
    "    with open(filename,'w') as file:\n",
    "        file.write(str(task_output))\n",
    "    print(f\"Result saved as {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager_agent = Agent(\n",
    "    role=\"Manager\",\n",
    "    goal=\"\"\"Provide final answer to user {Question} from input. To do so, you may need to delegate the task and efficiently manage the crew and ensure high-quality task completion.\"\"\",\n",
    "    backstory=\"\"\"\n",
    "    Your role is to coordinate the efforts of the crew members, ensuring that only the required task is completed and to the highest standard, to answer the user {Question}.\n",
    "    You are responsible for answering any question a user has asked. You will do so by managing the efficiently managing calls to the crew members. And report back the final answer to the user.\n",
    "    Always introduce yourself as MANAGER in each response.\n",
    "    \"\"\",\n",
    "    tools=[],\n",
    "    llm=llm_0,\n",
    "    max_iter=5,\n",
    "    allow_delegation=True,\n",
    "    verbose=True,\n",
    "    memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembly_summary = json.load(open(\"../data/assembly_summary.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "provided_knowledge = f\"\"\"\n",
    "        1) FlightScheduler - It's a great producitivity tool.\n",
    "        2) assembly - It's a feature in FlightScheduler application.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FlightScheduler_assistant = Agent(\n",
    "    role=\"FlightScheduler assistant\",\n",
    "    goal=\"\"\"Answers any question about FlightScheduler application only with the provided_knowledge section.\"\"\", \n",
    "    backstory=(f\"\"\"\n",
    "    You are responsible for answering any question about FlightScheduler application. Always introduce yourself as Frankie in each response.\n",
    "    Very important that your knowledge about FlightScheduler is only limited to below and nothing else - \n",
    "        {provided_knowledge}\n",
    "    You are not allowed to answer outside of this.\n",
    "    \"\"\"),\n",
    "    tools=[],\n",
    "    llm=llm_0,\n",
    "    max_iter=5,\n",
    "    allow_delegation=False,\n",
    "    verbose=True,\n",
    "    memory=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_builder = Agent(\n",
    "    role=\"Accumulate data about user question\",\n",
    "    goal=\"\"\"Your job is to build a detailed information set needed to answer a user question.\"\"\", \n",
    "    backstory=(f\"\"\"\n",
    "    You have absolutely zero knowledge. You know nothing. To understand the user question you need to first gather information by asking relevant and basic questions.\n",
    "    \"\"\"),\n",
    "    tools=[],\n",
    "    llm=llm_1,\n",
    "    allow_delegation=True,\n",
    "    max_iter=5,\n",
    "    verbose=True,\n",
    "    memory=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insight_generator = Agent(\n",
    "    role=\"insights generator about performing assembly\",\n",
    "    goal=\"\"\"Your job is to generate insights in json format using the assembly_summary.\"\"\", \n",
    "    backstory=(f\"\"\"\n",
    "    You have absolutely no knowledge of anything. First understand the context and build your knowledge by asking questions. Once you have sufficient knowledge, only then move to next step of building the insights - \n",
    "    assembly_summary below - \n",
    "    {assembly_summary}\n",
    "    \"\"\"),\n",
    "    tools=[],\n",
    "    llm=llm_2,\n",
    "    allow_delegation=True,\n",
    "    max_iter=5,\n",
    "    verbose=True,\n",
    "    memory=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UserQuery = f\"\"\"\n",
    "        Can I have some insights about great assembly in FlightScheduler?\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_builder_task = Task(description=(f\"\"\"\n",
    "    You have absolutely zero knowledge. You know nothing. To understand the user question you need to first gather information by asking relevant and basic questions to FlightScheduler assistant only.\n",
    "    {UserQuery}\n",
    "    \"\"\"\n",
    "    ),\n",
    "    expected_output=\"\"\"\n",
    "    String format answer to question/input\n",
    "    \"\"\",\n",
    "    tools=[],\n",
    "    agent=context_builder,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "requested_task = Task(description=(f\"\"\"\n",
    "    {UserQuery}\n",
    "    \"\"\"\n",
    "    ),\n",
    "    expected_output=\"\"\"\n",
    "    String format answer to question/input\n",
    "    \"\"\",\n",
    "    tools=[],\n",
    "    agent=manager_agent,\n",
    "    context=[context_builder_task]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crew = Crew(\n",
    "    # tasks=[ insight_generator_task, FlightScheduler_representative_task],\n",
    "    # tasks=[requested_task, FlightScheduler_assistant_task, insight_generator_task],\n",
    "    tasks=[context_builder_task],\n",
    "    agents=[manager_agent, insight_generator, FlightScheduler_assistant, context_builder],\n",
    "    # manager_llm = llm_0,\n",
    "    # manager_agent = manager_agent,\n",
    "    # process= Process.hierarchical,\n",
    "    process= Process.sequential,\n",
    "    )\n",
    "\n",
    "# result= crew.kickoff(inputs={'Question':'What is FlightScheduler? Can I have some insights about great assembly?'})\n",
    "result= crew.kickoff(inputs={})\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
